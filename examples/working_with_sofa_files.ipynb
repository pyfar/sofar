{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with SOFA files\n",
    "\n",
    "The Quick tour of SOFA and sofar showed how to access SOFA files. In many cases you will want to have a closer look at the data inside a SOFA file or use it for further processing. In this section, you will see examples of how to do that using [pyfar](https://pyfar.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data for specific source and receiver positions\n",
    "\n",
    "In most cases SOFA files contain data for lots of source or receiver positions and it is often important to get data for a specific position. An elegant way of doing that is to use pyfar Coordinates and Audio objects. Coordinate objects have built in methods to search specific positions and they can convert between a large variety of coordinate systems for you. For audio objects, there is a growing pool of functions for plotting and processing that comes in handy. If you installed sofar, pyfar was installed as a part of it.\n",
    "\n",
    "You have to options to get SOFA data into pyfar. The first option is to load the SOFA file with `sofar.read_sofa` and then manually generate Audio and Coordinates objects from the data inside the SOFA file. The second option is to use `pyfar.read_sofa`, which directly returns the Audio and Coordinates objects. Lets be lazy and do that. For more information on pyfar checkout the examples that are part of the [pyfar documentation](https://pyfar.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfar as pf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# select matplotlib backend for plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# load head-related impulse responses\n",
    "hrirs, source_coordinates, receiver_coordinates = pf.io.read_sofa(\n",
    "    os.path.join('resources', 'head_related_impulse_responses.sofa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SOFA file used in this example is contained head-realated impulse responses (HRIRs) from the [FABIAN database](https://depositonce.tu-berlin.de/handle/11303/6153.5>). Lets find the HRIR for the source position at the left ear on the horizontal plane. It has an azimuth angle of 90 degrees and an elevation of 0 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate point to find\n",
    "find = pf.Coordinates().from_spherical_elevation(np.pi/2, 0, 1.7)\n",
    "# index of corresponding point\n",
    "lateral, _ = source_coordinates.find_nearest(find, k=1)\n",
    "\n",
    "print(lateral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the HRIR for the desired source position is at index 134 in `hrirs` audio object. Note that you get more then the most closest point by using different values for `k`. We can use the `Coordinates.show` method to get visual feedback for checking if we got the correct source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_coordinates.show(lateral)\n",
    "plt.gca().view_init(azim=-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also find all sources on the horizontal plane, i.e., all sources that have an elevation of 0 degree. Lets get visual feedback right away. This time we don't get an index but a logical array with is `True` at the positions where `source_coordinates.elevation` is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal = source_coordinates.elevation == 0\n",
    "source_coordinates.show(horizontal)\n",
    "plt.gca().view_init(azim=-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, lets also find all sources in the median plane. This can be done in a similar way, considering that they have a lateral angle of 0 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = source_coordinates.lateral == 0\n",
    "source_coordinates.show(median)\n",
    "plt.gca().view_init(azim=-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Plotting data is a very common task and can be easy with the help of the [pyfar plot module](https://pyfar.readthedocs.io/en/stable/modules/pyfar.plot.html). Lets start with taking at the time signals and magnitude responses for the lateral source position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pf.plot.time_freq(hrirs[lateral], unit='ms', label=['left', 'right'])\n",
    "ax[0].set_xlim(0, 3)\n",
    "ax[0].legend()\n",
    "ax[1].set_ylim(-25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the entire horizontal plane is also easy, however, a few more lines are required for a nicer formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azimuth = np.round(source_coordinates.azimuth[horizontal] / np.pi * 180)\n",
    "\n",
    "ax, qm, cb = pf.plot.time_freq_2d(\n",
    "    hrirs[horizontal, 0], indices=azimuth, unit='ms',\n",
    "    cmap=mpl.colormaps['coolwarm'])\n",
    "\n",
    "ax[0].set_title(\"Left ear HRIR (Horizontal plane)\")\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_ylim(0, 3)\n",
    "qm[0].set_clim(-1.5, 1.5)\n",
    "\n",
    "ax[1].set_title(\"Left ear HRTFs (Horizontal plane)\")\n",
    "ax[1].set_xlabel(\"Azimuth angle in degrees\")\n",
    "ax[1].set_ylim(200, 20e3)\n",
    "qm[1].set_clim(-25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median plane HRIRs could be plotted in a similar way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing\n",
    "\n",
    "For detailed information about sofar refer to the [sofar documentation](https://sofar.readthedocs.io/). Pyfar also offers methods for digital signal processing we wont't detail all of them, but lets at least look at a few common tasks. For everything else, check out the [pyfar documentation](https://pyfar.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find HRIR onset\n",
    "\n",
    "Finding the onset or starting point of an HRIR is a common task, for example to compute the interaural time difference or to time align HRIRs for further processing. A common way of finding the onset is to detect the first sample in the HRIR that is less than 20 dB below the absolute maximum value. Lets find this point for our lateral HRIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-pass HRIR at 3 kHz\n",
    "hrir_onset = pf.dsp.filter.butterworth(hrirs[lateral], 10, 3000)\n",
    "# upsample by a factor of 10 for subsample accuracy\n",
    "hrir_onset = pf.dsp.resample(hrir_onset, 10 * hrirs.sampling_rate)\n",
    "# find the onset\n",
    "onset = pf.dsp.find_impulse_response_start(hrir_onset, 20) / 10\n",
    "# the low-pass introduces a low frequency group-delay of 15 samples, which we\n",
    "# need to correct. you can see the group delay in a simple plot if running:\n",
    "# lp = pf.dsp.filter.butterworth(pf.signals.impulse(2048), 10, 3000)\n",
    "# pf.plot.group_delay(lp, unit='samples')\n",
    "onset -= 15\n",
    "\n",
    "# plot the result\n",
    "ax = pf.plot.time(hrirs[lateral], unit='samples', label=['left', 'right'])\n",
    "ax.axvline(onset[0], color=pf.plot.color('b'), linestyle='--')\n",
    "ax.axvline(onset[1], color=pf.plot.color('r'), linestyle='--')\n",
    "ax.set_xlim(0, 120)\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align HRIRs\n",
    "\n",
    "Aligning HRIRs is often done as a pre-processing step before HRIR interpolation. Now that we already estimated the onsets, aligning the HRIRs can be done by means of a cyclic fractional time shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrirs_aligned = pf.dsp.fractional_time_shift(\n",
    "    hrirs[lateral], -onset, mode='cyclic')\n",
    "\n",
    "ax = pf.plot.time(hrirs_aligned, unit='samples',\n",
    "                  label=['left (aligned)', 'right (aligned)'])\n",
    "ax.set_xlim(0, 120)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute diffuse-field HRIR\n",
    "\n",
    "The diffuse field HRIR can be obtained by averaging across source positions. This is a common task and also easy if using pyfar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain energetic average using equal weights. Unequal weights can be realized\n",
    "# using the `weights` parameter.\n",
    "diffuse_field_hrir = pf.dsp.average(hrirs, mode='power')\n",
    "\n",
    "# obtain minimum phase version, since the energetic averaging resulted in zero-\n",
    "# phase HRIRs\n",
    "diffuse_field_hrir = pf.dsp.minimum_phase(diffuse_field_hrir)\n",
    "\n",
    "# plot\n",
    "ax = pf.plot.time_freq(diffuse_field_hrir, unit='samples')\n",
    "ax[1].set_ylim(-25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate headphone compensation filter\n",
    "\n",
    "If using HRIRs for binaural synthesis, i.e., spatial audio playback, we need a headphone compensation filter. A good and easy approximation is to use the inverted diffuse field HRIR. We can see from the plot above that the diffuse field HRIR does not contain energy above 20 kHz. A direct inversion would thous not be good. We use a regulated inversion insted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_inversion = 1 / diffuse_field_hrir\n",
    "regulated_inversion = pf.dsp.regularized_spectrum_inversion(\n",
    "    diffuse_field_hrir, [0, 20_000])\n",
    "\n",
    "ax = pf.plot.freq(direct_inversion, color='r', label='direct inversion')\n",
    "pf.plot.freq(regulated_inversion, color='b', label='regulated inversion')\n",
    "ax.set_ylim(-25, 25)\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sofar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
